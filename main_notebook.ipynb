{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from shared.plot import plot_geodesic, plot_hierarchy, plot_train_embed, get_dict_data\n",
    "from shared.io import read_data, read_ref\n",
    "from train import init_torch_objects, train\n",
    "\n",
    "OUT_DIMENSIONS = 3 # 50\n",
    "NEG_SAMPLES = 10 # 10\n",
    "EPOCH = 501\n",
    "DEVICE = \"cuda:0\" # or \"cpu\"\n",
    "torch.set_default_dtype(torch.float64)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot geodesic comparison between Poincar√© and Euclidean\n",
    "# plot_geodesic()\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load edge data\n",
    "data, weights, objects, neighbors, diff_summed, num_relations = read_data(Path(\"data\",\"opehr_concepts_11454.csv\"))\n",
    "\n",
    "# load concept reference \n",
    "ref = read_ref(Path('data','ref.csv'))\n",
    "\n",
    "# define fixed index clinical finding\n",
    "clinical_finding_concept_id = 441840\n",
    "fixed_index = objects.index(clinical_finding_concept_id)\n",
    "\n",
    "# initialize torch objects for the training loop\n",
    "model, optimizer, loss_func = init_torch_objects(objects, OUT_DIMENSIONS, fixed_index)\n",
    "\n",
    "if \"cuda:0\" == DEVICE:\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "# ToDo: implement function to load embedding and continue training\n",
    "\n",
    "# ensure that ref contains all concepts\n",
    "dict_data = dict(enumerate(objects))\n",
    "for key, value in dict_data.items():\n",
    "    try:\n",
    "        dict_data[key] = ref.loc[ref['concept_id'] == value].concept_name.values[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error at Key={key}, Value={value}, Error={e}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# plot_hierarchy(data, objects, ref, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train(data=data, weights=weights, objects=objects, neighbors=neighbors,\n",
    "      diff_summed=diff_summed, num_relations=num_relations,\n",
    "      model=model, optimizer=optimizer, loss_func=loss_func,\n",
    "      out_dimensions=OUT_DIMENSIONS, n_neg_samples=NEG_SAMPLES, n_epochs=EPOCH,\n",
    "      n_burn_in=10, device=DEVICE) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dict_data = get_dict_data(objects, ref, dict_type=\"name\")\n",
    "model = torch.load(\"output/poincare_model_dim_3.pt\")\n",
    "coordinates = model[\"state_dict\"][\"embedding.weight\"].numpy()\n",
    "# print(model.state_dict()['embedding.weight'])\n",
    "# coordinates = model.embedding.weight\n",
    "print(coordinates)\n",
    "#######################################################\n",
    "# some experiment with 3d plotting in TF projector  \n",
    "x_np = coordinates # .detach().numpy()\n",
    "x_df = pd.DataFrame(x_np)\n",
    "x_df.to_csv(Path('output','tf_proj_vec.tsv'), sep=\"\\t\", index=False, header=False)\n",
    "\n",
    "df = pd.Series(dict_data)\n",
    "df.to_string()\n",
    "print(df)\n",
    "df.to_csv(Path('output','tf_proj_lab.tsv'), sep=\"\\t\", index=False, header=False,\n",
    "          quoting=csv.QUOTE_NONNUMERIC)\n",
    "# df[\"index\"].map(dictData)\n",
    "###########################\n",
    "\n",
    "# print(len(objects))\n",
    "#print(data)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.axis('off')\n",
    "\n",
    "data, weights, objects, neighbors, diff_summed, num_relations = read_data(\"data/opehr_concepts.csv\")\n",
    "\n",
    "# add some jitter to better see labels\n",
    "jitter = 0.02\n",
    "jitter_x = np.random.uniform(low=-jitter, high = jitter, size=(coordinates.shape[0], ))\n",
    "jitter_y = np.random.uniform(low=-jitter, high = jitter, size=(coordinates.shape[0], ))\n",
    "\n",
    "for x in range(coordinates.shape[0]):\n",
    "    plt.annotate(dict_data[x], (coordinates[x,0].detach().numpy()+jitter_x[x],\n",
    "                               coordinates[x,1].detach().numpy()+jitter_y[x]), fontsize=4)\n",
    "    # plt.annotate(dictData[x], (coordinates[x,0]*100, coordinates[x,1]*100),\n",
    "    #              bbox={\"fc\":\"white\", \"alpha\":0.9}, fontsize=4)\n",
    "\n",
    "# Plot edges of original hierarchy\n",
    "for i in range(data.shape[0]):\n",
    "    x_values = [coordinates[data[i][0], 0].detach().numpy(), coordinates[data[i][1], 0].detach().numpy()]\n",
    "    y_values = [coordinates[data[i][0], 1].detach().numpy(), coordinates[data[i][1], 1].detach().numpy()]\n",
    "#\n",
    "#     x_val = [coordinates[data[x][0],0].detach().numpy(), coordinates[data[x][1],1].detach().numpy()]\n",
    "#     y_val = [coordinates[data[x][0],0].detach().numpy(), coordinates[data[x][1],1].detach().numpy()]\n",
    "    plt.plot(x_values, y_values, color=\"black\", linewidth=0.2)\n",
    "\n",
    "plt.savefig(Path(\"output\", \"hierarchy_embed.png\"), dpi=300, facecolor=\"white\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from shared.io import write_tensorflow_projector_data\n",
    "\n",
    "model_path = 'output/poincare_model_dim_3_epoch_500.pt'\n",
    "ref_csv_path = 'data/ref.csv'\n",
    "\n",
    "write_tensorflow_projector_data(model_path, ref_csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T09:47:26.908810Z",
     "start_time": "2024-11-04T09:47:23.230692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available keys in the state dictionary:\n",
      "embedding.weight\n",
      "First 100 embedding weights:\n",
      "Embedding 0: [0.4034566  0.85267115 0.33130244]\n",
      "Embedding 1: [0.37091265 0.85063698 0.35481152]\n",
      "Embedding 2: [0.35314391 0.91834867 0.17142104]\n",
      "Embedding 3: [ 0.11019133 -0.91036501  0.39208295]\n",
      "Embedding 4: [ 0.05754362 -0.88446279  0.43867873]\n",
      "Embedding 5: [ 0.142665  -0.9042851  0.3831774]\n",
      "Embedding 6: [ 0.10265174 -0.89466806  0.42437099]\n",
      "Embedding 7: [-0.21033209 -0.68707265  0.69173662]\n",
      "Embedding 8: [-0.53354435 -0.69008162  0.46336703]\n",
      "Embedding 9: [-0.36319214 -0.92464404  0.01070366]\n",
      "Embedding 10: [ 0.31208514 -0.73270328  0.59689635]\n",
      "Embedding 11: [-0.34486266 -0.80030032  0.47782676]\n",
      "Embedding 12: [-0.49515176 -0.84650664  0.13620161]\n",
      "Embedding 13: [0.53186368 0.83128565 0.08520911]\n",
      "Embedding 14: [0.59988687 0.33102292 0.7088905 ]\n",
      "Embedding 15: [-0.0367966  -0.77213641  0.61060392]\n",
      "Embedding 16: [ 0.58407405 -0.23120929  0.76146089]\n",
      "Embedding 17: [-0.3012234  -0.70799683  0.62379625]\n",
      "Embedding 18: [-0.27461178 -0.70844728  0.63915686]\n",
      "Embedding 19: [-0.34023226 -0.73220357  0.58423125]\n",
      "Embedding 20: [-0.20929965 -0.7621863   0.60231711]\n",
      "Embedding 21: [-0.52514988 -0.75418795  0.37482606]\n",
      "Embedding 22: [ 0.81851899 -0.2229473   0.51945226]\n",
      "Embedding 23: [ 0.77732004 -0.17805154  0.59438415]\n",
      "Embedding 24: [-0.0646503  -0.67482716  0.72290437]\n",
      "Embedding 25: [-0.12420364 -0.64844687  0.73783435]\n",
      "Embedding 26: [-0.22403097 -0.70575133  0.66225383]\n",
      "Embedding 27: [-0.9923828  -0.00861051 -0.00828016]\n",
      "Embedding 28: [-0.77554363 -0.60489087  0.06427758]\n",
      "Embedding 29: [-0.19224437 -0.69845631  0.68617347]\n",
      "Embedding 30: [-0.12362981 -0.63367084  0.761276  ]\n",
      "Embedding 31: [-0.13056244 -0.59780712  0.78703665]\n",
      "Embedding 32: [-0.12167858 -0.68265271  0.71598899]\n",
      "Embedding 33: [-0.21225337 -0.77098525  0.58653302]\n",
      "Embedding 34: [-0.58825353 -0.58403514  0.54491214]\n",
      "Embedding 35: [0.75086213 0.39512454 0.50479227]\n",
      "Embedding 36: [-0.34605814 -0.75406413  0.55213657]\n",
      "Embedding 37: [-0.46360258 -0.86897036  0.08842928]\n",
      "Embedding 38: [-0.13857258 -0.73138965  0.65947815]\n",
      "Embedding 39: [-0.38360213 -0.74476602  0.53957842]\n",
      "Embedding 40: [ 0.81214172 -0.06784901  0.56388321]\n",
      "Embedding 41: [ 0.76695682 -0.16321431  0.6130048 ]\n",
      "Embedding 42: [-0.48495658 -0.85752668  0.0851703 ]\n",
      "Embedding 43: [0.96954514 0.09417792 0.16029227]\n",
      "Embedding 44: [-0.07118233 -0.68906852  0.70774592]\n",
      "Embedding 45: [-0.00278412 -0.64744714  0.74675091]\n",
      "Embedding 46: [0.99038862 0.04010896 0.08370586]\n",
      "Embedding 47: [-0.22518908 -0.66042036  0.71131099]\n",
      "Embedding 48: [ 0.72275787 -0.33403263  0.58786479]\n",
      "Embedding 49: [-0.96601295  0.14082663 -0.15882874]\n",
      "Embedding 50: [-0.97432318  0.12929713 -0.15839165]\n",
      "Embedding 51: [-0.96898516  0.20062107 -0.08274978]\n",
      "Embedding 52: [-0.91151431  0.30754149 -0.19082634]\n",
      "Embedding 53: [ 0.02982637 -0.9672356   0.15332897]\n",
      "Embedding 54: [-0.97447262  0.14329862 -0.16854749]\n",
      "Embedding 55: [-0.83815835 -0.33291166 -0.42229377]\n",
      "Embedding 56: [-0.95156641  0.16880683  0.22434542]\n",
      "Embedding 57: [-0.35809573 -0.62397435 -0.68320549]\n",
      "Embedding 58: [-0.94738394 -0.19389768 -0.22909278]\n",
      "Embedding 59: [-0.72137739 -0.66981957 -0.14855966]\n",
      "Embedding 60: [-0.89776602  0.01900445  0.42918859]\n",
      "Embedding 61: [-0.86615189 -0.30721255 -0.39243673]\n",
      "Embedding 62: [-0.90683668 -0.36702549 -0.19370165]\n",
      "Embedding 63: [-0.89575243 -0.43565836  0.03619873]\n",
      "Embedding 64: [-0.73757369 -0.20757224 -0.63695156]\n",
      "Embedding 65: [-0.9737502   0.01427485 -0.21245521]\n",
      "Embedding 66: [-0.84943932 -0.32213582 -0.41706661]\n",
      "Embedding 67: [-0.80609484 -0.37370585 -0.45690358]\n",
      "Embedding 68: [-0.39733596 -0.22842887 -0.88411602]\n",
      "Embedding 69: [-0.85883088 -0.28300471 -0.42482868]\n",
      "Embedding 70: [-0.77527537 -0.39736285 -0.48805084]\n",
      "Embedding 71: [-0.21347378  0.52416969 -0.80486972]\n",
      "Embedding 72: [-0.94713662 -0.04049445 -0.29758203]\n",
      "Embedding 73: [-0.81015278 -0.35268768 -0.46635946]\n",
      "Embedding 74: [-0.82969924 -0.51123274 -0.19011383]\n",
      "Embedding 75: [-0.64684013  0.43765152 -0.6180527 ]\n",
      "Embedding 76: [-0.84817129 -0.40160249 -0.34163903]\n",
      "Embedding 77: [-0.497449   -0.60718903 -0.61367316]\n",
      "Embedding 78: [-0.45735321  0.66569789 -0.58220938]\n",
      "Embedding 79: [-0.75144231  0.38352099  0.52968855]\n",
      "Embedding 80: [-0.10699437 -0.86612847 -0.47655585]\n",
      "Embedding 81: [-0.16258645  0.52152866 -0.82985366]\n",
      "Embedding 82: [-0.6479032  -0.56403375 -0.50590707]\n",
      "Embedding 83: [-0.31989769 -0.28289394 -0.89371769]\n",
      "Embedding 84: [-0.65701441  0.6978774   0.2686665 ]\n",
      "Embedding 85: [-0.54355679  0.83210513  0.05209918]\n",
      "Embedding 86: [-0.69963996  0.6128338   0.35990318]\n",
      "Embedding 87: [-0.65675629  0.71820565  0.22693354]\n",
      "Embedding 88: [-0.66778137  0.68984467  0.27839507]\n",
      "Embedding 89: [-0.4888269   0.86322158  0.08507751]\n",
      "Embedding 90: [ 0.5682514   0.69508684 -0.42992592]\n",
      "Embedding 91: [ 0.88751798 -0.33255992  0.26066221]\n",
      "Embedding 92: [ 0.56485833  0.68457932 -0.45368505]\n",
      "Embedding 93: [ 0.56221825  0.72235267 -0.39511048]\n",
      "Embedding 94: [ 0.56535251  0.69320128 -0.44602077]\n",
      "Embedding 95: [ 0.54745736  0.69935714 -0.45582648]\n",
      "Embedding 96: [ 0.62316765 -0.29326679  0.7144714 ]\n",
      "Embedding 97: [ 0.50590476  0.73138431 -0.45501661]\n",
      "Embedding 98: [ 0.51498747  0.76175269 -0.39054216]\n",
      "Embedding 99: [ 0.5780487   0.69779782 -0.41501963]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Load the tensor from the .pt file\n",
    "file_path = \"D:/git/omop-poincare/output/embedding.pt\"\n",
    "tensor = torch.load(file_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Print the contents of the tensor\n",
    "print(tensor)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Print the result\n",
    "if cuda_available:\n",
    "    print(\"CUDA is available.\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-04T10:05:18.682910Z",
     "start_time": "2024-11-04T10:05:18.652706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from shared.io import convert_embedding_for_plp\n",
    "\n",
    "convert_embedding_for_plp(\"output/poincare_model_dim_10_epoch_500.pt\", \"output/embedding_501.pt\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
